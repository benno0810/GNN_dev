{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import math\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from dgl.data import citation_graph as citegrh\n",
    "from dgl.data import CoraBinary\n",
    "from dgl.data import CoraGraphDataset\n",
    "from dgl import DGLGraph\n",
    "import dgl.function as fn\n",
    "import networkx as nx\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import RedditDataset, KarateClubDataset\n",
    "from dgl.nn import GraphConv\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import MSELoss\n",
    "from losses import compute_loss_multiclass\n",
    "\n",
    "\n",
    "class MyModel(th.nn.Module):\n",
    "    def __init__(self, g, dropout, n_features):\n",
    "        '''\n",
    "\n",
    "        :param g:\n",
    "        :param dropout:\n",
    "\n",
    "        c_hat = ReLU(f1*c+f2*(Q C)+b) = (nX1)\n",
    "        Q= nXn\n",
    "        C = nX1\n",
    "        Q*C = nX1\n",
    "        so dimmension of  input is [n,2], output [n,1], Linear layer  [2,1]\n",
    "        '''\n",
    "        super(MyModel, self).__init__()\n",
    "        self.g = g\n",
    "        self.layers = th.nn.ModuleList()\n",
    "        self.layers.append(th.nn.Linear(n_features, 2))\n",
    "        self.layers.append(th.nn.ReLU(inplace=True))\n",
    "        self.dropout = th.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features):\n",
    "        h = features.float()\n",
    "        for i, layers in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layers(h)\n",
    "        return h\n",
    "\n",
    "\n",
    "class ModularityScore(th.nn.Module):\n",
    "    def __init__(self,n_classes,cuda):\n",
    "        super(ModularityScore, self).__init__()\n",
    "        ## define C as parameter\n",
    "        #self.params = th.nn.ParameterList([C])\n",
    "        self.cuda=cuda\n",
    "\n",
    "\n",
    "    def forward(self,C,Q):\n",
    "        # -tf.linalg.trace(tf.matmul(tf.matmul(tf.transpose(C),Q),C))\n",
    "        C=th.sigmoid(C)\n",
    "        Q=Q.float()\n",
    "        if self.cuda:\n",
    "            C=C.cuda()\n",
    "            Q=Q.cuda()\n",
    "        temp = th.matmul(th.matmul(C.t(), Q), C)\n",
    "        loss = -temp.trace()\n",
    "        return loss\n",
    "\n",
    "\n",
    "class GCN(th.nn.Module):\n",
    "    def __init__(self,\n",
    "                 g,\n",
    "                 in_feats,\n",
    "                 n_hidden,\n",
    "                 n_classes,\n",
    "                 n_layers,\n",
    "                 activation,\n",
    "                 dropout):\n",
    "        super(GCN, self).__init__()\n",
    "        self.g = g\n",
    "        self.layers = th.nn.ModuleList()\n",
    "        # input layer\n",
    "        self.layers.append(GraphConv(in_feats, n_hidden, activation=activation))\n",
    "        # output layer\n",
    "        for i in range(n_layers - 1):\n",
    "            self.layers.append(GraphConv(n_hidden, n_hidden, activation=activation))\n",
    "        # output layer\n",
    "        self.layers.append(GraphConv(n_hidden, n_classes))\n",
    "        self.dropout = th.nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, features):\n",
    "        h = features\n",
    "        for i, layers in enumerate(self.layers):\n",
    "            if i != 0:\n",
    "                h = self.dropout(h)\n",
    "            h = layers(self.g, h)\n",
    "        return h\n",
    "\n",
    "\n",
    "def evaluate(model, features, labels, mask):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "\n",
    "\n",
    "def Q2(G1: dgl.DGLGraph):\n",
    "    # calculate matrix Q with diag set to 0\n",
    "    # A=np.array(nx.adjacency_matrix(G1).todense())\n",
    "    G1 = dgl.to_networkx(G1)\n",
    "    A = np.array(nx.adjacency_matrix(G1).todense())\n",
    "    T = A.sum(axis=(0, 1))\n",
    "    Q = A * 0\n",
    "    w_in = A.sum(axis=1)\n",
    "    w_out = w_in.reshape(w_in.shape[0], 1)\n",
    "    K = w_in * w_out / T\n",
    "    Q = (A - K) / T\n",
    "    # set Qii to zero for every i\n",
    "    for i in range(Q.shape[0]):\n",
    "        Q[i][i] = 0\n",
    "    return Q\n",
    "\n",
    "\n",
    "# a utility function to convert a scipy.coo_matrix to torch.SparseFloat\n",
    "def sparse2th(mat):\n",
    "    value = mat.data\n",
    "    indices = th.LongTensor([mat.row, mat.col])\n",
    "    # tensor = th.FloatTensor(th.from_numpy(value).float())\n",
    "    tensor = th.sparse.FloatTensor(indices, th.from_numpy(value).float(), mat.shape)\n",
    "    return tensor.to_dense()\n",
    "\n",
    "\n",
    "# network visualization utility function\n",
    "def visualize(labels, g):\n",
    "    pos = nx.spring_layout(g, seed=1)\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis('off')\n",
    "    nx.draw_networkx(g, pos=pos, node_size=50, cmap=plt.get_cmap('coolwarm'),\n",
    "                     node_color=labels, edge_color='k',\n",
    "                     arrows=False, width=0.5, style='dotted', with_labels=False)\n",
    "\n",
    "def load_cora_binary():\n",
    "    data = CoraBinary()\n",
    "    g,features,labels=data[1]\n",
    "    n_edges=g.number_of_edges()\n",
    "    features=sparse2th(features)\n",
    "    labels=th.LongTensor(labels)\n",
    "    in_feats=features.shape[1]\n",
    "    n_classes=2\n",
    "    print(th.max(features))\n",
    "\n",
    "    return g,features,n_classes,in_feats,n_edges,labels\n",
    "\n",
    "def load_kara():\n",
    "    data =KarateClubDataset()\n",
    "    n_classes = data.num_classes\n",
    "    g = data[0]\n",
    "    n_edges=g.number_of_edges()\n",
    "    n=len(g.ndata['label'])\n",
    "    labels=g.ndata['label']\n",
    "    #construct features, train,val,test masks\n",
    "    g.ndata['feat']= th.eye(n)\n",
    "    in_feats=g.ndata['feat'].shape[1]\n",
    "    features=torch.FloatTensor(g.ndata['feat'])\n",
    "\n",
    "    return g,features,n_classes,in_feats,labels,n\n",
    "\n",
    "def load_cora():\n",
    "\n",
    "    data = citegrh.load_cora()\n",
    "    features = torch.FloatTensor(data.features)\n",
    "    labels = torch.LongTensor(data.labels)\n",
    "    train_mask = torch.BoolTensor(data.train_mask)\n",
    "    val_mask = torch.BoolTensor(data.val_mask)\n",
    "    test_mask = torch.BoolTensor(data.test_mask)\n",
    "    in_feats = features.shape[1]\n",
    "    n_classes = data.num_labels\n",
    "    n_edges = data.graph.number_of_edges()\n",
    "    g = DGLGraph(data.graph)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benno\\anaconda3\\envs\\gpu\\lib\\site-packages\\dgl\\data\\dgl_dataset.py\", line 165, in _load\n",
      "    self.load()\n",
      "  File \"C:\\Users\\benno\\anaconda3\\envs\\gpu\\lib\\site-packages\\dgl\\data\\citation_graph.py\", line 874, in load\n",
      "    for i in range(len(lables)):\n",
      "NameError: name 'lables' is not defined\n",
      "\n",
      "Loading from cache failed, re-processing.\n",
      "Done saving data into cached files.\n",
      "Done saving data into cached files.\n",
      "tensor(1.)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0420, -0.0268,  0.0022,  ..., -0.0291, -0.0110,  0.0214],\n",
      "        [-0.0426,  0.0371, -0.0140,  ...,  0.0183,  0.0403, -0.0368],\n",
      "        [-0.0041, -0.0357,  0.0410,  ...,  0.0240, -0.0267,  0.0428],\n",
      "        ...,\n",
      "        [ 0.0113,  0.0322, -0.0434,  ...,  0.0006, -0.0240, -0.0202],\n",
      "        [-0.0291, -0.0247,  0.0289,  ...,  0.0316,  0.0290,  0.0089],\n",
      "        [-0.0197,  0.0198,  0.0315,  ...,  0.0355, -0.0189,  0.0174]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.1249, -0.0577,  0.0352,  ..., -0.1347, -0.0059, -0.1224],\n",
      "        [ 0.1481,  0.0528,  0.1817,  ...,  0.1152,  0.2017, -0.1807],\n",
      "        [-0.0687, -0.1115,  0.0009,  ..., -0.0540, -0.2395, -0.1064],\n",
      "        ...,\n",
      "        [-0.0344, -0.0549,  0.0729,  ...,  0.1049, -0.1352, -0.1272],\n",
      "        [-0.0721, -0.1190,  0.0207,  ..., -0.2103,  0.1677,  0.0322],\n",
      "        [ 0.2356, -0.1621, -0.0485,  ...,  0.2963, -0.2850,  0.1546]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.3699,  0.2807],\n",
      "        [-0.0983, -0.3719],\n",
      "        [ 0.2543,  0.2244],\n",
      "        [-0.3029, -0.3795],\n",
      "        [ 0.2354, -0.1397],\n",
      "        [-0.2301,  0.3619],\n",
      "        [-0.3171, -0.1429],\n",
      "        [-0.1655, -0.0853],\n",
      "        [ 0.1698, -0.1490],\n",
      "        [ 0.0584, -0.2995],\n",
      "        [-0.0901,  0.0548],\n",
      "        [-0.3351,  0.4187],\n",
      "        [-0.2852,  0.3494],\n",
      "        [ 0.4133,  0.1955],\n",
      "        [ 0.3368, -0.2556],\n",
      "        [ 0.1132, -0.1866],\n",
      "        [ 0.0371,  0.1349],\n",
      "        [ 0.0311, -0.3135],\n",
      "        [-0.1051,  0.2946],\n",
      "        [-0.3393, -0.1895],\n",
      "        [ 0.2062, -0.1494],\n",
      "        [-0.0058, -0.3006],\n",
      "        [-0.1344,  0.1320],\n",
      "        [-0.4160, -0.1726],\n",
      "        [-0.3704,  0.2300],\n",
      "        [-0.3350,  0.1362],\n",
      "        [-0.1704,  0.1584],\n",
      "        [ 0.3688, -0.4140],\n",
      "        [-0.2782,  0.2312],\n",
      "        [-0.3507, -0.1521],\n",
      "        [ 0.0264, -0.1556],\n",
      "        [-0.1360,  0.0700]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0.], requires_grad=True)\n",
      "Epoch 0 | Time(s) 0.25041818618774414 | Modularity 0.0027023260481655598 | Accuracy 0.6415094339622641 | ETputs(KTEPS) 10.718071402321176\n",
      "Epoch 100 | Time(s) 0.01309873089931979 | Modularity 0.002920942148193717 | Accuracy 0.6095791001451378 | ETputs(KTEPS) 204.90534698589607\n",
      "Epoch 200 | Time(s) 0.011569754994330715 | Modularity 0.003131250385195017 | Accuracy 0.5660377358490566 | ETputs(KTEPS) 231.9841691820773\n",
      "Epoch 300 | Time(s) 0.010976936333995324 | Modularity 0.0033028926700353622 | Accuracy 0.5457184325108854 | ETputs(KTEPS) 244.51266895734037\n",
      "Epoch 400 | Time(s) 0.010709722143158948 | Modularity 0.003446907503530383 | Accuracy 0.5283018867924528 | ETputs(KTEPS) 250.61341126524553\n",
      "Epoch 500 | Time(s) 0.010676930764478124 | Modularity 0.003537457436323166 | Accuracy 0.5108853410740203 | ETputs(KTEPS) 251.3831043027458\n",
      "Epoch 600 | Time(s) 0.010593550375813058 | Modularity 0.0037349089980125427 | Accuracy 0.5007256894049347 | ETputs(KTEPS) 253.3617063952464\n",
      "Epoch 700 | Time(s) 0.01056958741366268 | Modularity 0.0039293053559958935 | Accuracy 0.502177068214804 | ETputs(KTEPS) 253.93611831343122\n",
      "Epoch 800 | Time(s) 0.010494225331757697 | Modularity 0.003950529266148806 | Accuracy 0.5050798258345428 | ETputs(KTEPS) 255.7597073771287\n",
      "Epoch 900 | Time(s) 0.010387822076033277 | Modularity 0.0040096985176205635 | Accuracy 0.5123367198838897 | ETputs(KTEPS) 258.3794736138684\n",
      "Epoch 1000 | Time(s) 0.010371594281344267 | Modularity 0.004203301854431629 | Accuracy 0.5224963715529753 | ETputs(KTEPS) 258.7837440602358\n",
      "Epoch 1100 | Time(s) 0.01030744042426862 | Modularity 0.004338322672992945 | Accuracy 0.5370101596516691 | ETputs(KTEPS) 260.3944228171901\n",
      "Epoch 1200 | Time(s) 0.010293142285374778 | Modularity 0.004380013793706894 | Accuracy 0.555878084179971 | ETputs(KTEPS) 260.7561350641792\n",
      "Epoch 1300 | Time(s) 0.010284094696865918 | Modularity 0.004648818634450436 | Accuracy 0.5689404934687954 | ETputs(KTEPS) 260.98553923447923\n",
      "Epoch 1400 | Time(s) 0.01025280247919054 | Modularity 0.004560760222375393 | Accuracy 0.5805515239477503 | ETputs(KTEPS) 261.78208401532595\n",
      "Epoch 1500 | Time(s) 0.01020099368594155 | Modularity 0.004464532248675823 | Accuracy 0.5979680696661829 | ETputs(KTEPS) 263.1116225176124\n",
      "Epoch 1600 | Time(s) 0.010196912593948775 | Modularity 0.004860689397901297 | Accuracy 0.6153846153846154 | ETputs(KTEPS) 263.21692720920106\n",
      "Epoch 1700 | Time(s) 0.010220955568926954 | Modularity 0.0045940326526761055 | Accuracy 0.6516690856313497 | ETputs(KTEPS) 262.59775633500567\n",
      "Epoch 1800 | Time(s) 0.010239529517013322 | Modularity 0.004694683477282524 | Accuracy 0.683599419448476 | ETputs(KTEPS) 262.1214183269303\n",
      "Epoch 1900 | Time(s) 0.010254042704189406 | Modularity 0.005126552656292915 | Accuracy 0.6937590711175616 | ETputs(KTEPS) 261.75042150969597\n",
      "Epoch 2000 | Time(s) 0.010256618574105281 | Modularity 0.0052168844267725945 | Accuracy 0.7097242380261248 | ETputs(KTEPS) 261.6846849288372\n",
      "Epoch 2100 | Time(s) 0.010249424752367502 | Modularity 0.004854713566601276 | Accuracy 0.7285921625544267 | ETputs(KTEPS) 261.86835503914756\n",
      "Epoch 2200 | Time(s) 0.010242014568212734 | Modularity 0.005598671734333038 | Accuracy 0.737300435413643 | ETputs(KTEPS) 262.0578190085866\n",
      "Epoch 2300 | Time(s) 0.010238266260610461 | Modularity 0.005025630351155996 | Accuracy 0.7445573294629898 | ETputs(KTEPS) 262.15376038090704\n",
      "Epoch 2400 | Time(s) 0.01023187820040549 | Modularity 0.005068065598607063 | Accuracy 0.7474600870827286 | ETputs(KTEPS) 262.3174306251645\n",
      "Epoch 2500 | Time(s) 0.010209219496710593 | Modularity 0.006109498906880617 | Accuracy 0.7489114658925979 | ETputs(KTEPS) 262.89962723054236\n",
      "Epoch 2600 | Time(s) 0.01019484123235847 | Modularity 0.005705574527382851 | Accuracy 0.7561683599419449 | ETputs(KTEPS) 263.2704069466989\n",
      "Epoch 2700 | Time(s) 0.010178577718978368 | Modularity 0.0061131371185183525 | Accuracy 0.7590711175616836 | ETputs(KTEPS) 263.69106510780716\n",
      "Epoch 2800 | Time(s) 0.010178472177763574 | Modularity 0.005522090010344982 | Accuracy 0.7590711175616836 | ETputs(KTEPS) 263.6937993369582\n",
      "Epoch 2900 | Time(s) 0.010185977336827001 | Modularity 0.006231231614947319 | Accuracy 0.7561683599419449 | ETputs(KTEPS) 263.49950635528154\n",
      "Epoch 3000 | Time(s) 0.010191965405045649 | Modularity 0.006583608221262693 | Accuracy 0.760522496371553 | ETputs(KTEPS) 263.3446929354033\n",
      "Epoch 3100 | Time(s) 0.01017694740824375 | Modularity 0.005924389697611332 | Accuracy 0.7561683599419449 | ETputs(KTEPS) 263.73330747743165\n",
      "Epoch 3200 | Time(s) 0.010162233747716473 | Modularity 0.005848333239555359 | Accuracy 0.7634252539912917 | ETputs(KTEPS) 264.1151607640509\n",
      "Epoch 3300 | Time(s) 0.010141737495036387 | Modularity 0.007523707114160061 | Accuracy 0.7663280116110305 | ETputs(KTEPS) 264.6489323267946\n",
      "Epoch 3400 | Time(s) 0.01012626951913629 | Modularity 0.006045198533684015 | Accuracy 0.772133526850508 | ETputs(KTEPS) 265.0531861637561\n",
      "Epoch 3500 | Time(s) 0.010118530464662684 | Modularity 0.0067329928278923035 | Accuracy 0.7706821480406386 | ETputs(KTEPS) 265.25590938065875\n",
      "Epoch 3600 | Time(s) 0.010126511609014687 | Modularity 0.00794132612645626 | Accuracy 0.7779390420899854 | ETputs(KTEPS) 265.0468496585424\n",
      "Epoch 3700 | Time(s) 0.010115699940712122 | Modularity 0.006826390512287617 | Accuracy 0.7764876632801161 | ETputs(KTEPS) 265.3301319464655\n",
      "Epoch 3800 | Time(s) 0.01010308006003605 | Modularity 0.008241897448897362 | Accuracy 0.7735849056603774 | ETputs(KTEPS) 265.66155905434084\n",
      "Epoch 3900 | Time(s) 0.010094436551631643 | Modularity 0.009126737713813782 | Accuracy 0.7735849056603774 | ETputs(KTEPS) 265.8890356357893\n",
      "Epoch 4000 | Time(s) 0.010099965731700163 | Modularity 0.007929045706987381 | Accuracy 0.7750362844702468 | ETputs(KTEPS) 265.74347589872394\n",
      "Epoch 4100 | Time(s) 0.010097432619070198 | Modularity 0.008621621876955032 | Accuracy 0.7808417997097242 | ETputs(KTEPS) 265.81014216732166\n",
      "Epoch 4200 | Time(s) 0.010104050950702104 | Modularity 0.00892894621938467 | Accuracy 0.7793904208998549 | ETputs(KTEPS) 265.63603183468666\n",
      "Epoch 4300 | Time(s) 0.010103630703622534 | Modularity 0.006908338516950607 | Accuracy 0.7866473149492017 | ETputs(KTEPS) 265.6470806120897\n",
      "Epoch 4400 | Time(s) 0.01010459874115649 | Modularity 0.007619843818247318 | Accuracy 0.7706821480406386 | ETputs(KTEPS) 265.6216311755108\n",
      "Epoch 4500 | Time(s) 0.010099281127970369 | Modularity 0.00872170552611351 | Accuracy 0.7503628447024674 | ETputs(KTEPS) 265.76148995066126\n",
      "Epoch 4600 | Time(s) 0.010100284884012774 | Modularity 0.008988792076706886 | Accuracy 0.7184325108853411 | ETputs(KTEPS) 265.7350788440004\n",
      "Epoch 4700 | Time(s) 0.010102730866468504 | Modularity 0.008147986605763435 | Accuracy 0.7082728592162555 | ETputs(KTEPS) 265.67074145351506\n",
      "Epoch 4800 | Time(s) 0.010098980754843554 | Modularity 0.009682304225862026 | Accuracy 0.6850507982583455 | ETputs(KTEPS) 265.7693944720839\n",
      "Epoch 4900 | Time(s) 0.010084962776742938 | Modularity 0.009463957510888577 | Accuracy 0.6661828737300436 | ETputs(KTEPS) 266.13881076384405\n",
      "Epoch 5000 | Time(s) 0.010068702783567432 | Modularity 0.009250640869140625 | Accuracy 0.6415094339622641 | ETputs(KTEPS) 266.5685995201295\n",
      "Epoch 5100 | Time(s) 0.010058568005841331 | Modularity 0.010149055160582066 | Accuracy 0.6168359941944848 | ETputs(KTEPS) 266.8371878026092\n",
      "Epoch 5200 | Time(s) 0.010054791026380377 | Modularity 0.013255350291728973 | Accuracy 0.5878084179970973 | ETputs(KTEPS) 266.9374224643844\n",
      "Epoch 5300 | Time(s) 0.01004870296356656 | Modularity 0.010075604543089867 | Accuracy 0.5776487663280117 | ETputs(KTEPS) 267.0991479926654\n",
      "Epoch 5400 | Time(s) 0.010043210220478173 | Modularity 0.011002474464476109 | Accuracy 0.5674891146589259 | ETputs(KTEPS) 267.2452274798855\n",
      "Epoch 5500 | Time(s) 0.010029372291724436 | Modularity 0.015361689031124115 | Accuracy 0.5660377358490566 | ETputs(KTEPS) 267.6139564800737\n",
      "Epoch 5600 | Time(s) 0.010015127935956108 | Modularity 0.019461188465356827 | Accuracy 0.579100145137881 | ETputs(KTEPS) 267.9945795164491\n",
      "Epoch 5700 | Time(s) 0.010002438634388322 | Modularity 0.019477074965834618 | Accuracy 0.5878084179970973 | ETputs(KTEPS) 268.3345630107067\n",
      "Epoch 5800 | Time(s) 0.009988120333364638 | Modularity 0.025061778724193573 | Accuracy 0.6124818577648766 | ETputs(KTEPS) 268.71922948648114\n",
      "Epoch 5900 | Time(s) 0.009978866318568721 | Modularity 0.027033088728785515 | Accuracy 0.6531204644412192 | ETputs(KTEPS) 268.96842931001095\n",
      "Epoch 6000 | Time(s) 0.00997892142812166 | Modularity 0.03346359357237816 | Accuracy 0.690856313497823 | ETputs(KTEPS) 268.96694390600203\n",
      "Epoch 6100 | Time(s) 0.00996897224910219 | Modularity 0.04603426530957222 | Accuracy 0.7039187227866474 | ETputs(KTEPS) 269.2353768204864\n",
      "Epoch 6200 | Time(s) 0.009953693081690139 | Modularity 0.0700286477804184 | Accuracy 0.7155297532656023 | ETputs(KTEPS) 269.64865984638703\n",
      "Epoch 6300 | Time(s) 0.009941282470611103 | Modularity 0.09855552762746811 | Accuracy 0.7358490566037735 | ETputs(KTEPS) 269.9852869018228\n",
      "Epoch 6400 | Time(s) 0.009926294204015841 | Modularity 0.1689683198928833 | Accuracy 0.7735849056603774 | ETputs(KTEPS) 270.3929527813255\n",
      "Epoch 6500 | Time(s) 0.009916538532798684 | Modularity 0.19198808073997498 | Accuracy 0.818577648766328 | ETputs(KTEPS) 270.65895938615495\n",
      "Epoch 6600 | Time(s) 0.009907987763928277 | Modularity 0.2627711296081543 | Accuracy 0.8708272859216255 | ETputs(KTEPS) 270.8925428603738\n",
      "Epoch 6700 | Time(s) 0.009905990175908402 | Modularity 0.31151700019836426 | Accuracy 0.8809869375907112 | ETputs(KTEPS) 270.9471695749861\n",
      "Epoch 6800 | Time(s) 0.009896183553784582 | Modularity 0.3330879807472229 | Accuracy 0.8708272859216255 | ETputs(KTEPS) 271.2156646461516\n",
      "Epoch 6900 | Time(s) 0.009885830976637942 | Modularity 0.3656275272369385 | Accuracy 0.8679245283018868 | ETputs(KTEPS) 271.49968539243605\n",
      "Epoch 7000 | Time(s) 0.009888062322502425 | Modularity 0.37099477648735046 | Accuracy 0.8621190130624092 | ETputs(KTEPS) 271.4384186163529\n",
      "Epoch 7100 | Time(s) 0.009927560839581163 | Modularity 0.3997310996055603 | Accuracy 0.8490566037735849 | ETputs(KTEPS) 270.35845394156615\n",
      "Epoch 7200 | Time(s) 0.009937766094602424 | Modularity 0.3969363272190094 | Accuracy 0.8403483309143687 | ETputs(KTEPS) 270.08081841026444\n",
      "Epoch 7300 | Time(s) 0.009943307254301688 | Modularity 0.4161168336868286 | Accuracy 0.8359941944847605 | ETputs(KTEPS) 269.9303090366481\n",
      "Epoch 7400 | Time(s) 0.009938965261248283 | Modularity 0.4176328182220459 | Accuracy 0.8301886792452831 | ETputs(KTEPS) 270.048232331069\n",
      "Epoch 7500 | Time(s) 0.009943408276967693 | Modularity 0.41950422525405884 | Accuracy 0.8287373004354136 | ETputs(KTEPS) 269.92756660883117\n",
      "Epoch 7600 | Time(s) 0.009946552205597032 | Modularity 0.42252615094184875 | Accuracy 0.8156748911465893 | ETputs(KTEPS) 269.84224729546827\n",
      "Epoch 7700 | Time(s) 0.009949872964636845 | Modularity 0.430398166179657 | Accuracy 0.795355587808418 | ETputs(KTEPS) 269.7521877454404\n",
      "Epoch 7800 | Time(s) 0.009975803187223234 | Modularity 0.4324992299079895 | Accuracy 0.795355587808418 | ETputs(KTEPS) 269.0510177102935\n",
      "Epoch 7900 | Time(s) 0.009976136263466051 | Modularity 0.4289935827255249 | Accuracy 0.7997097242380261 | ETputs(KTEPS) 269.0420348235587\n",
      "Epoch 8000 | Time(s) 0.00997771079682392 | Modularity 0.4313376545906067 | Accuracy 0.7910014513788098 | ETputs(KTEPS) 268.99957862622796\n",
      "Epoch 8100 | Time(s) 0.009983444402224045 | Modularity 0.43709796667099 | Accuracy 0.7822931785195936 | ETputs(KTEPS) 268.84508911594446\n",
      "Epoch 8200 | Time(s) 0.009982332022157243 | Modularity 0.4373583197593689 | Accuracy 0.7793904208998549 | ETputs(KTEPS) 268.8750478387686\n",
      "Epoch 8300 | Time(s) 0.009998356257701636 | Modularity 0.4406338334083557 | Accuracy 0.7764876632801161 | ETputs(KTEPS) 268.4441252963497\n",
      "Epoch 8400 | Time(s) 0.010006972514877801 | Modularity 0.4426589012145996 | Accuracy 0.7677793904208998 | ETputs(KTEPS) 268.2129880950088\n",
      "Epoch 8500 | Time(s) 0.010009151615124424 | Modularity 0.4433199167251587 | Accuracy 0.7663280116110305 | ETputs(KTEPS) 268.1545952350563\n",
      "Epoch 8600 | Time(s) 0.010009067860498995 | Modularity 0.4460495710372925 | Accuracy 0.760522496371553 | ETputs(KTEPS) 268.1568391191016\n",
      "Epoch 8700 | Time(s) 0.010022667273339588 | Modularity 0.4449591040611267 | Accuracy 0.7561683599419449 | ETputs(KTEPS) 267.7929863180704\n",
      "Epoch 8800 | Time(s) 0.01003175439543107 | Modularity 0.4473712742328644 | Accuracy 0.7518142235123367 | ETputs(KTEPS) 267.5504098487917\n",
      "Epoch 8900 | Time(s) 0.010036592335664025 | Modularity 0.44554823637008667 | Accuracy 0.7460087082728593 | ETputs(KTEPS) 267.42144248129665\n",
      "Epoch 9000 | Time(s) 0.010040209884312984 | Modularity 0.4465571939945221 | Accuracy 0.7358490566037735 | ETputs(KTEPS) 267.32508891009667\n",
      "Epoch 9100 | Time(s) 0.010042759025899831 | Modularity 0.45092934370040894 | Accuracy 0.7387518142235123 | ETputs(KTEPS) 267.25723410051785\n",
      "Epoch 9200 | Time(s) 0.010048294466431407 | Modularity 0.4528200030326843 | Accuracy 0.737300435413643 | ETputs(KTEPS) 267.1100064758758\n",
      "Epoch 9300 | Time(s) 0.010058766320858857 | Modularity 0.4548792243003845 | Accuracy 0.7285921625544267 | ETputs(KTEPS) 266.8319269366255\n",
      "Epoch 9400 | Time(s) 0.010069123558155616 | Modularity 0.45217466354370117 | Accuracy 0.7242380261248186 | ETputs(KTEPS) 266.55745999124815\n",
      "Epoch 9500 | Time(s) 0.010080841262395 | Modularity 0.45215147733688354 | Accuracy 0.7198838896952104 | ETputs(KTEPS) 266.2476206239098\n",
      "Epoch 9600 | Time(s) 0.010082936239744173 | Modularity 0.4554058909416199 | Accuracy 0.7198838896952104 | ETputs(KTEPS) 266.1923011493822\n",
      "Epoch 9700 | Time(s) 0.010082206705429789 | Modularity 0.4515987038612366 | Accuracy 0.7213352685050798 | ETputs(KTEPS) 266.2115624503639\n",
      "Epoch 9800 | Time(s) 0.010091900643055906 | Modularity 0.4574890732765198 | Accuracy 0.714078374455733 | ETputs(KTEPS) 265.9558486484726\n",
      "Epoch 9900 | Time(s) 0.01010170289692572 | Modularity 0.4577574133872986 | Accuracy 0.7111756168359942 | ETputs(KTEPS) 265.69777664088986\n",
      "Epoch 10000 | Time(s) 0.010112409507759856 | Modularity 0.45900464057922363 | Accuracy 0.7082728592162555 | ETputs(KTEPS) 265.4164665642156\n",
      "Epoch 10100 | Time(s) 0.010113894095598807 | Modularity 0.4576781690120697 | Accuracy 0.7024673439767779 | ETputs(KTEPS) 265.37750688609424\n",
      "Epoch 10200 | Time(s) 0.01010877671703125 | Modularity 0.4551909565925598 | Accuracy 0.6995645863570392 | ETputs(KTEPS) 265.51184927034757\n",
      "Epoch 10300 | Time(s) 0.010103858080827753 | Modularity 0.4589639902114868 | Accuracy 0.6966618287373004 | ETputs(KTEPS) 265.64110249063543\n",
      "Epoch 10400 | Time(s) 0.010098265129927776 | Modularity 0.4518921375274658 | Accuracy 0.6850507982583455 | ETputs(KTEPS) 265.78822851912946\n",
      "Epoch 10500 | Time(s) 0.01009906524590635 | Modularity 0.4521571397781372 | Accuracy 0.6850507982583455 | ETputs(KTEPS) 265.76717098525114\n",
      "Epoch 10600 | Time(s) 0.010099189819654039 | Modularity 0.458903431892395 | Accuracy 0.683599419448476 | ETputs(KTEPS) 265.763892740848\n",
      "Epoch 10700 | Time(s) 0.010094450540759164 | Modularity 0.4541624188423157 | Accuracy 0.6777939042089985 | ETputs(KTEPS) 265.88866716049574\n",
      "Epoch 10800 | Time(s) 0.010088405943768917 | Modularity 0.45741838216781616 | Accuracy 0.6719883889695211 | ETputs(KTEPS) 266.0479777439732\n",
      "Epoch 10900 | Time(s) 0.010084769865994322 | Modularity 0.4598005712032318 | Accuracy 0.6719883889695211 | ETputs(KTEPS) 266.14390171166957\n",
      "Epoch 11000 | Time(s) 0.010088837110999498 | Modularity 0.4580727517604828 | Accuracy 0.6719883889695211 | ETputs(KTEPS) 266.0366076357533\n",
      "Epoch 11100 | Time(s) 0.010087876757590923 | Modularity 0.46112382411956787 | Accuracy 0.6661828737300436 | ETputs(KTEPS) 266.0619339922392\n",
      "Epoch 11200 | Time(s) 0.010087826158114708 | Modularity 0.46187764406204224 | Accuracy 0.6676342525399129 | ETputs(KTEPS) 266.0632685309485\n",
      "Epoch 11300 | Time(s) 0.01008397118727324 | Modularity 0.4601493179798126 | Accuracy 0.6661828737300436 | ETputs(KTEPS) 266.1649810530417\n",
      "Epoch 11400 | Time(s) 0.010079477891703674 | Modularity 0.45584526658058167 | Accuracy 0.6676342525399129 | ETputs(KTEPS) 266.2836338188882\n",
      "Epoch 11500 | Time(s) 0.010075412473619715 | Modularity 0.4625411033630371 | Accuracy 0.660377358490566 | ETputs(KTEPS) 266.39107897840137\n",
      "Epoch 11600 | Time(s) 0.010068228918666954 | Modularity 0.4606815576553345 | Accuracy 0.6560232220609579 | ETputs(KTEPS) 266.581145669398\n",
      "Epoch 11700 | Time(s) 0.010064587757308487 | Modularity 0.4629056453704834 | Accuracy 0.6589259796806967 | ETputs(KTEPS) 266.67758925853576\n",
      "Epoch 11800 | Time(s) 0.010063550844201394 | Modularity 0.46196234226226807 | Accuracy 0.6473149492017417 | ETputs(KTEPS) 266.7050667853005\n",
      "Epoch 11900 | Time(s) 0.01006025943863483 | Modularity 0.4643328785896301 | Accuracy 0.6444121915820029 | ETputs(KTEPS) 266.79232442977803\n",
      "Epoch 12000 | Time(s) 0.010056272445842729 | Modularity 0.4625316262245178 | Accuracy 0.6429608127721336 | ETputs(KTEPS) 266.89809911719004\n",
      "Epoch 12100 | Time(s) 0.010051524971114851 | Modularity 0.46117883920669556 | Accuracy 0.6415094339622641 | ETputs(KTEPS) 267.02415879312167\n",
      "Epoch 12200 | Time(s) 0.010053988255767409 | Modularity 0.46485668420791626 | Accuracy 0.6415094339622641 | ETputs(KTEPS) 266.9587363462793\n",
      "Epoch 12300 | Time(s) 0.010056168090501517 | Modularity 0.46245262026786804 | Accuracy 0.637155297532656 | ETputs(KTEPS) 266.90086878471664\n",
      "Epoch 12400 | Time(s) 0.010055169320166106 | Modularity 0.4619799852371216 | Accuracy 0.6386066763425254 | ETputs(KTEPS) 266.9273797923138\n",
      "Epoch 12500 | Time(s) 0.010052263369589613 | Modularity 0.4625571668148041 | Accuracy 0.6386066763425254 | ETputs(KTEPS) 267.00454428200834\n",
      "Epoch 12600 | Time(s) 0.010046705197989019 | Modularity 0.4633585214614868 | Accuracy 0.637155297532656 | ETputs(KTEPS) 267.15226007997506\n",
      "Epoch 12700 | Time(s) 0.010040525169543756 | Modularity 0.4629790782928467 | Accuracy 0.6342525399129173 | ETputs(KTEPS) 267.3166945630954\n",
      "Epoch 12800 | Time(s) 0.01003413054730946 | Modularity 0.4629001319408417 | Accuracy 0.6328011611030478 | ETputs(KTEPS) 267.4870520515287\n",
      "Epoch 12900 | Time(s) 0.010030394736652863 | Modularity 0.4636613726615906 | Accuracy 0.6298984034833092 | ETputs(KTEPS) 267.58667734104046\n",
      "Epoch 13000 | Time(s) 0.010027177681712754 | Modularity 0.4619099497795105 | Accuracy 0.6269956458635704 | ETputs(KTEPS) 267.6725281227432\n",
      "Epoch 13100 | Time(s) 0.01002530707320078 | Modularity 0.46351879835128784 | Accuracy 0.6226415094339622 | ETputs(KTEPS) 267.72247277839034\n",
      "Epoch 13200 | Time(s) 0.010019675898430934 | Modularity 0.4639013409614563 | Accuracy 0.613933236574746 | ETputs(KTEPS) 267.87293593202054\n",
      "Epoch 13300 | Time(s) 0.0100172113972529 | Modularity 0.46452540159225464 | Accuracy 0.6095791001451378 | ETputs(KTEPS) 267.9388398188397\n",
      "Epoch 13400 | Time(s) 0.010018516481745537 | Modularity 0.46499955654144287 | Accuracy 0.6095791001451378 | ETputs(KTEPS) 267.9039361656431\n",
      "Epoch 13500 | Time(s) 0.010021876638955112 | Modularity 0.46270519495010376 | Accuracy 0.6081277213352685 | ETputs(KTEPS) 267.81411273486157\n",
      "Epoch 13600 | Time(s) 0.010022099794127399 | Modularity 0.46454936265945435 | Accuracy 0.5979680696661829 | ETputs(KTEPS) 267.8081495030343\n",
      "Epoch 13700 | Time(s) 0.01001903287042415 | Modularity 0.46412548422813416 | Accuracy 0.5979680696661829 | ETputs(KTEPS) 267.89012819022463\n",
      "Epoch 13800 | Time(s) 0.010013835999026055 | Modularity 0.46515533328056335 | Accuracy 0.5892597968069666 | ETputs(KTEPS) 268.0291548874024\n",
      "Epoch 13900 | Time(s) 0.010009145352507862 | Modularity 0.4664696455001831 | Accuracy 0.5820029027576198 | ETputs(KTEPS) 268.1547630165552\n",
      "Epoch 14000 | Time(s) 0.010009523426053456 | Modularity 0.46176964044570923 | Accuracy 0.5776487663280117 | ETputs(KTEPS) 268.1446344402278\n",
      "Epoch 14100 | Time(s) 0.010011102077715972 | Modularity 0.465201199054718 | Accuracy 0.579100145137881 | ETputs(KTEPS) 268.1023506866842\n",
      "Epoch 14200 | Time(s) 0.010012518712378128 | Modularity 0.46498793363571167 | Accuracy 0.5776487663280117 | ETputs(KTEPS) 268.0644178653933\n",
      "Epoch 14300 | Time(s) 0.010011328091096915 | Modularity 0.4640553891658783 | Accuracy 0.5747460087082729 | ETputs(KTEPS) 268.09629807127027\n",
      "Epoch 14400 | Time(s) 0.010006193154123573 | Modularity 0.46675002574920654 | Accuracy 0.5747460087082729 | ETputs(KTEPS) 268.23387862485123\n",
      "Epoch 14500 | Time(s) 0.010001337073620546 | Modularity 0.4625244438648224 | Accuracy 0.5747460087082729 | ETputs(KTEPS) 268.36411774174667\n",
      "Epoch 14600 | Time(s) 0.00999620447223476 | Modularity 0.46396034955978394 | Accuracy 0.5732946298984035 | ETputs(KTEPS) 268.50191064568753\n",
      "Epoch 14700 | Time(s) 0.0099908706971751 | Modularity 0.46469753980636597 | Accuracy 0.5660377358490566 | ETputs(KTEPS) 268.645254387978\n",
      "Epoch 14800 | Time(s) 0.009987568389756495 | Modularity 0.46616390347480774 | Accuracy 0.5616835994194485 | ETputs(KTEPS) 268.7340797338398\n",
      "Epoch 14900 | Time(s) 0.009988068286288258 | Modularity 0.4667952060699463 | Accuracy 0.5587808417997098 | ETputs(KTEPS) 268.72062976227625\n",
      "Epoch 15000 | Time(s) 0.009982492167046449 | Modularity 0.46595799922943115 | Accuracy 0.5587808417997098 | ETputs(KTEPS) 268.87073439038056\n",
      "Epoch 15100 | Time(s) 0.009977454705298653 | Modularity 0.46732014417648315 | Accuracy 0.5515239477503628 | ETputs(KTEPS) 269.0064830436793\n",
      "Epoch 15200 | Time(s) 0.009976761253732857 | Modularity 0.46515506505966187 | Accuracy 0.5529753265602322 | ETputs(KTEPS) 269.0251807915888\n",
      "Epoch 15300 | Time(s) 0.009982549507675137 | Modularity 0.46716174483299255 | Accuracy 0.5544267053701016 | ETputs(KTEPS) 268.86918997360266\n",
      "Epoch 15400 | Time(s) 0.009982287469649267 | Modularity 0.4661645293235779 | Accuracy 0.548621190130624 | ETputs(KTEPS) 268.876247870099\n",
      "Epoch 15500 | Time(s) 0.009983061421387395 | Modularity 0.46655604243278503 | Accuracy 0.5471698113207547 | ETputs(KTEPS) 268.8554028376389\n",
      "Epoch 15600 | Time(s) 0.0099788219009819 | Modularity 0.46742507815361023 | Accuracy 0.5529753265602322 | ETputs(KTEPS) 268.969626538369\n",
      "Epoch 15700 | Time(s) 0.009973808501406192 | Modularity 0.46548712253570557 | Accuracy 0.5515239477503628 | ETputs(KTEPS) 269.1048258668278\n",
      "Epoch 15800 | Time(s) 0.009967783389004881 | Modularity 0.46589383482933044 | Accuracy 0.5515239477503628 | ETputs(KTEPS) 269.2674885933645\n",
      "Epoch 15900 | Time(s) 0.009962653223129723 | Modularity 0.46802711486816406 | Accuracy 0.5500725689404935 | ETputs(KTEPS) 269.4061451189238\n",
      "Epoch 16000 | Time(s) 0.009961275315032915 | Modularity 0.46509265899658203 | Accuracy 0.5500725689404935 | ETputs(KTEPS) 269.4434111212126\n",
      "Epoch 16100 | Time(s) 0.009962646319002745 | Modularity 0.46797528862953186 | Accuracy 0.5399129172714079 | ETputs(KTEPS) 269.40633181773603\n",
      "Epoch 16200 | Time(s) 0.009958629335608647 | Modularity 0.46888095140457153 | Accuracy 0.5370101596516691 | ETputs(KTEPS) 269.5150014674143\n",
      "Epoch 16300 | Time(s) 0.009953987451427795 | Modularity 0.46440190076828003 | Accuracy 0.532656023222061 | ETputs(KTEPS) 269.64068551392523\n",
      "Epoch 16400 | Time(s) 0.009951595591085799 | Modularity 0.4656861424446106 | Accuracy 0.532656023222061 | ETputs(KTEPS) 269.705493499375\n",
      "Epoch 16500 | Time(s) 0.009954809730728138 | Modularity 0.46763092279434204 | Accuracy 0.5268505079825835 | ETputs(KTEPS) 269.61841286781487\n",
      "Epoch 16600 | Time(s) 0.009956782441937444 | Modularity 0.4666563868522644 | Accuracy 0.521044992743106 | ETputs(KTEPS) 269.56499407832126\n",
      "Epoch 16700 | Time(s) 0.009957235035486017 | Modularity 0.46708664298057556 | Accuracy 0.5224963715529753 | ETputs(KTEPS) 269.5527413418129\n",
      "Epoch 16800 | Time(s) 0.009952975187931137 | Modularity 0.46848198771476746 | Accuracy 0.5152394775036284 | ETputs(KTEPS) 269.66810921568333\n",
      "Epoch 16900 | Time(s) 0.009948766934759525 | Modularity 0.46674031019210815 | Accuracy 0.5050798258345428 | ETputs(KTEPS) 269.7821767864015\n",
      "Epoch 17000 | Time(s) 0.009945667895784967 | Modularity 0.46440789103507996 | Accuracy 0.5036284470246735 | ETputs(KTEPS) 269.8662400679491\n",
      "Epoch 17100 | Time(s) 0.00994038375509628 | Modularity 0.46736687421798706 | Accuracy 0.5036284470246735 | ETputs(KTEPS) 270.0096964188083\n",
      "Epoch 17200 | Time(s) 0.009938824503208744 | Modularity 0.4687495827674866 | Accuracy 0.5036284470246735 | ETputs(KTEPS) 270.052056873876\n",
      "Epoch 17300 | Time(s) 0.009937976951592506 | Modularity 0.46740394830703735 | Accuracy 0.5007256894049347 | ETputs(KTEPS) 270.0750880258284\n",
      "Epoch 17400 | Time(s) 0.009934953091973635 | Modularity 0.4697628319263458 | Accuracy 0.5050798258345428 | ETputs(KTEPS) 270.1572896371681\n",
      "Epoch 17500 | Time(s) 0.009930706045966946 | Modularity 0.46505698561668396 | Accuracy 0.5007256894049347 | ETputs(KTEPS) 270.2728272870412\n",
      "Epoch 17600 | Time(s) 0.009927245461326466 | Modularity 0.4695396423339844 | Accuracy 0.5007256894049347 | ETputs(KTEPS) 270.36704294822255\n",
      "Epoch 17700 | Time(s) 0.009929985429235693 | Modularity 0.466938316822052 | Accuracy 0.5036284470246735 | ETputs(KTEPS) 270.29244092320755\n",
      "Epoch 17800 | Time(s) 0.009928874156226081 | Modularity 0.46337777376174927 | Accuracy 0.5108853410740203 | ETputs(KTEPS) 270.32269296282186\n",
      "Epoch 17900 | Time(s) 0.00992738394142962 | Modularity 0.46826398372650146 | Accuracy 0.5108853410740203 | ETputs(KTEPS) 270.36327151596834\n",
      "Epoch 18000 | Time(s) 0.0099274092571953 | Modularity 0.46777141094207764 | Accuracy 0.5123367198838897 | ETputs(KTEPS) 270.36258206587587\n",
      "Epoch 18100 | Time(s) 0.009924226317983407 | Modularity 0.46615439653396606 | Accuracy 0.5166908563134979 | ETputs(KTEPS) 270.44929387960457\n",
      "Epoch 18200 | Time(s) 0.009921357301714446 | Modularity 0.46897733211517334 | Accuracy 0.5166908563134979 | ETputs(KTEPS) 270.5275012660007\n",
      "Epoch 18300 | Time(s) 0.009924804804123305 | Modularity 0.4675712287425995 | Accuracy 0.5195936139332366 | ETputs(KTEPS) 270.43353022770987\n",
      "Epoch 18400 | Time(s) 0.00992565731348975 | Modularity 0.4669651687145233 | Accuracy 0.5195936139332366 | ETputs(KTEPS) 270.4103028372975\n",
      "Epoch 18500 | Time(s) 0.00992812573487717 | Modularity 0.46858423948287964 | Accuracy 0.5239477503628447 | ETputs(KTEPS) 270.34307095559825\n",
      "Epoch 18600 | Time(s) 0.009930298165745404 | Modularity 0.4673624634742737 | Accuracy 0.521044992743106 | ETputs(KTEPS) 270.28392855901006\n",
      "Epoch 18700 | Time(s) 0.009927472585816095 | Modularity 0.4679192304611206 | Accuracy 0.5239477503628447 | ETputs(KTEPS) 270.3608573882916\n",
      "Epoch 18800 | Time(s) 0.009930209513452673 | Modularity 0.4671797752380371 | Accuracy 0.5195936139332366 | ETputs(KTEPS) 270.28634152823525\n",
      "Epoch 18900 | Time(s) 0.009934240822741344 | Modularity 0.4702087640762329 | Accuracy 0.5341074020319303 | ETputs(KTEPS) 270.1766594842174\n",
      "Epoch 19000 | Time(s) 0.00993544058726716 | Modularity 0.4649564027786255 | Accuracy 0.5341074020319303 | ETputs(KTEPS) 270.14403401895436\n",
      "Epoch 19100 | Time(s) 0.009938199022953238 | Modularity 0.4671972692012787 | Accuracy 0.5355587808417998 | ETputs(KTEPS) 270.06905313538607\n",
      "Epoch 19200 | Time(s) 0.009936551663796235 | Modularity 0.4676385521888733 | Accuracy 0.5355587808417998 | ETputs(KTEPS) 270.1138272927355\n",
      "Epoch 19300 | Time(s) 0.009934040371182484 | Modularity 0.47007399797439575 | Accuracy 0.5341074020319303 | ETputs(KTEPS) 270.1821111766344\n",
      "Epoch 19400 | Time(s) 0.009931553664216553 | Modularity 0.4674612283706665 | Accuracy 0.5341074020319303 | ETputs(KTEPS) 270.2497605858455\n",
      "Epoch 19500 | Time(s) 0.009927761492976885 | Modularity 0.465690553188324 | Accuracy 0.5428156748911466 | ETputs(KTEPS) 270.3529896340399\n",
      "Epoch 19600 | Time(s) 0.009927784324355237 | Modularity 0.4699450135231018 | Accuracy 0.5428156748911466 | ETputs(KTEPS) 270.35236789094057\n",
      "Epoch 19700 | Time(s) 0.009928822717075571 | Modularity 0.46820151805877686 | Accuracy 0.5471698113207547 | ETputs(KTEPS) 270.3240934480643\n",
      "Epoch 19800 | Time(s) 0.009931162953178098 | Modularity 0.4681659936904907 | Accuracy 0.548621190130624 | ETputs(KTEPS) 270.26039273085195\n",
      "Epoch 19900 | Time(s) 0.009929056677001965 | Modularity 0.4689442217350006 | Accuracy 0.5515239477503628 | ETputs(KTEPS) 270.3177237588719\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dropout = 0.5\n",
    "    gpu = 0\n",
    "    lr = 5e-2\n",
    "    n_epochs = 20000\n",
    "    n_hidden =32  # hidden node number for each layer\n",
    "    n_layers = 2  # number of layer\n",
    "    weight_decay = 5e-4  # weight decay not used here\n",
    "    self_loop = True  # check cycle in the network\n",
    "\n",
    "    # load cora_binary, train_masks,val_masks,test_masks are used for future accuracy comparement with supervised algorithm\n",
    "    g, features, n_classes, in_feats, n_edges,labels = load_cora_binary()\n",
    "    n = len(labels)\n",
    "    train_mask = [True] * n\n",
    "    train_mask=th.BoolTensor(train_mask)\n",
    "    val_mask = train_mask\n",
    "    test_mask = train_mask\n",
    "\n",
    "\n",
    "    #calculate matrix Q, initial community attachment C (with overlap)\n",
    "    Q = Q2(g)\n",
    "    # NOT OVERLAPING CASE\n",
    "    C_init = Q[0:2] * 0\n",
    "    C_init[0] = np.random.randint(2, size=(1, Q.shape[0]))\n",
    "    C_init[1] = 1 - C_init[0]\n",
    "    C = th.tensor(data=C_init.T, requires_grad=True)\n",
    "    C=C.float()\n",
    "    Q = th.from_numpy(Q)\n",
    "    Q=Q.float()\n",
    "    Q_C = th.matmul(Q,C)\n",
    "\n",
    "    if gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "        torch.cuda.set_device(gpu)\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        g=g.to('cuda:0')\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "        test_mask = test_mask.cuda()\n",
    "\n",
    "    degs = g.in_degrees().float()\n",
    "    norm = torch.pow(degs, -0.5)\n",
    "    norm[torch.isinf(norm)] = 0\n",
    "    if cuda:\n",
    "        norm = norm.cuda()\n",
    "    g.ndata['norm'] = norm.unsqueeze(1)\n",
    "    model = GCN(g,\n",
    "            in_feats,\n",
    "            n_hidden,\n",
    "            n_classes,\n",
    "            n_layers,\n",
    "            F.relu,\n",
    "            dropout)\n",
    "\n",
    "\n",
    "    #print initial model parameter\n",
    "    for p in model.parameters():\n",
    "        print(p)\n",
    "\n",
    "\n",
    "\n",
    "    # use crossentropyLoss as loss, must consider the permutations,\n",
    "    # loss_fcn = torch.th.nn.CrossEntropyLoss()\n",
    "    loss_fcn =ModularityScore(n_classes,cuda)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "    optimizer = torch.optim.SGD(model.parameters(),\n",
    "                                  lr=lr)\n",
    "\n",
    "    # train and evaluate (with modularity score and labels)\n",
    "    dur = []\n",
    "    M=[]\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        C_hat = model(features)\n",
    "        loss = loss_fcn(C_hat,Q)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        dur.append(time.time() - t0)\n",
    "        if epoch % 100 == 0:\n",
    "            #record modularity\n",
    "            M.append(str(-loss.item()))\n",
    "            acc_1 = evaluate(model, features, labels, val_mask)\n",
    "            acc_2 = evaluate(model, features, 1 - labels, val_mask)\n",
    "            acc = max(acc_1, acc_2)\n",
    "            print(\"Epoch {} | Time(s) {} | Modularity {} | Accuracy {} | \"\n",
    "                  \"ETputs(KTEPS) {}\".format(epoch, np.mean(dur), -loss,\n",
    "                                                acc, n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    with open('modularity_history.txt','w') as f:\n",
    "        for line in M:\n",
    "            f.write(line+'\\n')\n",
    "    f.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\benno\\anaconda3\\envs\\gpu\\lib\\site-packages\\dgl\\data\\dgl_dataset.py\", line 165, in _load\n",
      "    self.load()\n",
      "  File \"C:\\Users\\benno\\anaconda3\\envs\\gpu\\lib\\site-packages\\dgl\\data\\citation_graph.py\", line 874, in load\n",
      "    for i in range(len(lables)):\n",
      "NameError: name 'lables' is not defined\n",
      "\n",
      "Loading from cache failed, re-processing.\n",
      "Done saving data into cached files.\n",
      "Done saving data into cached files.\n",
      "tensor(1.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\benno\\anaconda3\\envs\\gpu\\lib\\site-packages\\dgl\\base.py:45: DGLWarning: DGLGraph.__len__ is deprecated.Please directly call DGLGraph.number_of_nodes.\n",
      "  return warnings.warn(message, category=category, stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pycombo\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "g, features, n_classes, in_feats, n_edges,labels = load_cora_binary()\n",
    "nx_g = dgl.to_networkx(g)\n",
    "partition = pycombo.execute(nx_g,max_communities=2)\n",
    "print(partition)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "gpu",
   "language": "python",
   "display_name": "gpu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}