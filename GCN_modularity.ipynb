{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., -0., 0.],\n",
      "        [1., -0., 0., 0.],\n",
      "        [1., 0., -0., 0.],\n",
      "        [1., 0., 0., -0.],\n",
      "        [0., -0., -0., 1.],\n",
      "        [0., -0., -0., 1.],\n",
      "        [0., -0., -0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., -0.],\n",
      "        [1., -0., 0., -0.],\n",
      "        [0., -0., -0., 1.],\n",
      "        [1., -0., -0., -0.],\n",
      "        [1., -0., -0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [-0., -0., -0., 1.],\n",
      "        [1., 0., -0., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [1., 0., -0., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [1., 0., -0., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [-0., -0., 1., -0.],\n",
      "        [-0., -0., 1., -0.],\n",
      "        [-0., -0., 1., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [-0., -0., 1., -0.],\n",
      "        [-0., -0., 1., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [-0., 1., -0., -0.],\n",
      "        [0., -0., 1., -0.],\n",
      "        [-0., 1., 0., -0.],\n",
      "        [-0., 1., -0., -0.]], dtype=torch.float64)\n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0., 0., 0., 0.], requires_grad=True)\n",
      "GCN(\n",
      "  (layers): ModuleList(\n",
      "    (0): MyGraphConv(in=4, out=8, normalization=none, activation=<function relu at 0x000001C48939DE58>)\n",
      "    (1): MyGraphConv(in=8, out=4, normalization=none, activation=functools.partial(<function softmax at 0x000001C4893A4D38>, dim=1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      ")\n",
      "Epoch 0 | Time(s) 0.00800466537475586 | Eval_Modularity 0.3414745330810547 | Train_Modularity 0.3414745330810547 | Eval_Accuracy 0.8823529411764706 | ETputs(KTEPS) 19.488634776910704\n",
      "Epoch 1000 | Time(s) 0.004929511339871676 | Eval_Modularity 0.4157966673374176 | Train_Modularity 0.4157966673374176 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 31.64613878422703\n",
      "Epoch 2000 | Time(s) 0.0047323852703012505 | Eval_Modularity 0.417776882648468 | Train_Modularity 0.417776882648468 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 32.96434907339433\n",
      "Epoch 3000 | Time(s) 0.004694744889953064 | Eval_Modularity 0.4185119867324829 | Train_Modularity 0.4185119867324829 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 33.22864259011092\n",
      "Epoch 4000 | Time(s) 0.004704333936771849 | Eval_Modularity 0.41887715458869934 | Train_Modularity 0.41887715458869934 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 33.16091121436172\n",
      "Epoch 5000 | Time(s) 0.004762030439218553 | Eval_Modularity 0.4190903604030609 | Train_Modularity 0.4190903604030609 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 32.759135413170426\n",
      "Epoch 6000 | Time(s) 0.004708042940960748 | Eval_Modularity 0.41922813653945923 | Train_Modularity 0.41922813653945923 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 33.134786992441036\n",
      "Epoch 7000 | Time(s) 0.004702121968644633 | Eval_Modularity 0.4193236827850342 | Train_Modularity 0.4193236827850342 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 33.17651074137627\n",
      "Epoch 8000 | Time(s) 0.0046583652317546305 | Eval_Modularity 0.4193933308124542 | Train_Modularity 0.4193933308124542 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 33.488142779487625\n",
      "Epoch 9000 | Time(s) 0.004628216924965084 | Eval_Modularity 0.4194461703300476 | Train_Modularity 0.4194461703300476 | Eval_Accuracy 0.6470588235294118 | ETputs(KTEPS) 33.70628527771024\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 1., 0., 0.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import math\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import dgl.function as fn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CoraGraphDataset\n",
    "from GraphSAGE.losses import compute_loss_multiclass\n",
    "from utils import *\n",
    "from model import *\n",
    "from loss import *\n",
    "import community as community_louvain\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def train(g, features, n_classes, in_feats, n_edges, labels,train_mask,val_mask,test_mask,Q,cuda):\n",
    "    #sethyperparameter\n",
    "    dropout = 0.0\n",
    "    gpu = 0\n",
    "    lr = 5e-2\n",
    "    n_epochs = 10000\n",
    "    n_hidden =8  # 隐藏层节点的数量\n",
    "    n_layers = 0 # 输入层 + 输出层的数量\n",
    "    weight_decay = 5e-4  # 权重衰减\n",
    "    self_loop = True  # 自循环\n",
    "\n",
    "\n",
    "    #run single train of some model\n",
    "    degs = g.in_degrees().float()\n",
    "    norm = torch.pow(degs, -0.5)\n",
    "    norm[torch.isinf(norm)] = 0\n",
    "\n",
    "    if cuda:\n",
    "        torch.cuda.set_device(gpu)\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        g=g.to('cuda:0')\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "\n",
    "    if cuda:\n",
    "        norm = norm.cuda()\n",
    "    # g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "    model = GCN(g,\n",
    "                in_feats,\n",
    "                n_hidden,\n",
    "                n_classes,\n",
    "                n_layers,\n",
    "                F.relu,\n",
    "                dropout)\n",
    "\n",
    "    for p in model.parameters():\n",
    "        print(p)\n",
    "\n",
    "    print(model)\n",
    "    # kernal_weights_analysis(model)\n",
    "\n",
    "\n",
    "    # use crossentropyLoss as loss, must consider the permutations,\n",
    "    # loss_fcn = torch.th.nn.CrossEntropyLoss()\n",
    "    loss_fcn = ModularityScore(n_classes, cuda)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    for p in loss_fcn.parameters():\n",
    "        print(p)\n",
    "\n",
    "    #optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = lr)\n",
    "    # train and evaluate (with modularity score and labels)\n",
    "    dur = []\n",
    "    M=[]\n",
    "    #P= [[1],[2],[3],[4],[5],[6]]\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        C_hat = model(features)\n",
    "        #use train_mask to train\n",
    "        loss = loss_fcn(C_hat[val_mask],Q['val'])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #C_out=C_construction(model,features)\n",
    "\n",
    "        #use eval_mask to see overfitting\n",
    "        modularity_score=evaluate_M(C_hat[train_mask],Q['train'],cuda)\n",
    "        dur.append(time.time() - t0)\n",
    "        if epoch % 1000 == 0:\n",
    "            #record modularity\n",
    "            #for i,p in enumerate(model.parameters()):\n",
    "            #    #print(p)\n",
    "            #    P[i].append(np.mean(np.abs(p.grad.cpu().detach().numpy())))\n",
    "            M.append(str(-loss.item()))\n",
    "            acc_1 = evaluate(model, features, labels, val_mask)\n",
    "            acc_2 = evaluate(model, features, 1 - labels, val_mask)\n",
    "            acc = max(acc_1, acc_2)\n",
    "            #acc=0.5\n",
    "            print(\"Epoch {} | Time(s) {} | Eval_Modularity {} | Train_Modularity {} | Eval_Accuracy {} | \"\n",
    "                  \"ETputs(KTEPS) {}\".format(epoch, np.mean(dur),modularity_score, -loss,\n",
    "                                                acc, n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    C_out=C_construction(model,features,test_mask)\n",
    "    print(C_out)\n",
    "    modularity_score=evaluate_M(C_out,Q['test'],cuda)\n",
    "    with open('modularity_history.txt','w') as f:\n",
    "        for line in M:\n",
    "            f.write(line+'\\n')\n",
    "    f.close()\n",
    "\n",
    "def main():\n",
    "    gpu=0\n",
    "    if gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "    #prepare training data, set hyperparameters\n",
    "    # load cora_binary, train_masks,val_masks,test_masks are used for future accuracy comparement with supervised algorithm\n",
    "    #g, features, n_classes, in_feats, n_edges,labels = load_cora_binary()\n",
    "    g, features, n_classes, in_feats, n_edges, labels = load_kara()\n",
    "    #g, features, n_classes, in_feats, n_edges, labels=load_les_miserables()\n",
    "    #g, features, n_classes, in_feats, n_edges, labels = load_citation_graph()\n",
    "\n",
    "    #graph visualization\n",
    "\n",
    "    #visualize(labels,g)\n",
    "    n = len(labels)\n",
    "    if 'train_mask' not in g.ndata:\n",
    "        train_mask = [True] * n\n",
    "        train_mask=th.BoolTensor(train_mask)\n",
    "    else:\n",
    "        train_mask=g.ndata['train_mask']\n",
    "    if 'val_mask' not in g.ndata:\n",
    "        val_mask = [True] * n\n",
    "        val_mask=th.BoolTensor(train_mask)\n",
    "    else:\n",
    "        val_mask=g.ndata['val_mask']\n",
    "    if 'test_mask' not in g.ndata:\n",
    "        test_mask = [True] * n\n",
    "        test_mask=th.BoolTensor(test_mask)\n",
    "    else:\n",
    "        test_mask=g.ndata['test_mask']\n",
    "\n",
    "    #calculate matrix Q, initial community attachment C (with overlap)\n",
    "\n",
    "    #overwrite n_classes\n",
    "    n_classes=4\n",
    "    #construct Q['train'], Q['eval'],Q['test'] seperately\n",
    "    Q={}\n",
    "    Q['train'] = Q2(g,train_mask)\n",
    "    Q['train'] = th.from_numpy(Q['train'])\n",
    "    Q['val']= Q2(g,val_mask)\n",
    "    Q['val'] = th.from_numpy(Q['val'])\n",
    "    Q['test'] = Q2(g, test_mask)\n",
    "    Q['test'] = th.from_numpy(Q['test'])\n",
    "\n",
    "    #generate random input features\n",
    "\n",
    "    nx_g =  nx.karate_club_graph()\n",
    "    partition = community_louvain.best_partition(nx_g)\n",
    "    n_classes=np.max(list(partition.values()))+1\n",
    "    C_init = Q['train'][0:n_classes] * 0\n",
    "    C_init = C_init.T\n",
    "    for node in partition.keys():\n",
    "        C_init[node][partition[node]]=1\n",
    "\n",
    "    #try C*C.T\n",
    "    features=C_init.float()\n",
    "    #features=th.matmul(features,features.t())\n",
    "    in_feats=features.shape[1]\n",
    "\n",
    "    print(C_init)\n",
    "\n",
    "    train(g, features, n_classes, in_feats, n_edges, labels,train_mask,val_mask,test_mask,Q,cuda)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}