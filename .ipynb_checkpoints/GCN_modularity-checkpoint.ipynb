{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import math\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import dgl.function as fn\n",
    "import torch.nn.functional as F\n",
    "from dgl.data import CoraGraphDataset\n",
    "from GraphSAGE.losses import compute_loss_multiclass\n",
    "from utils import *\n",
    "from model import *\n",
    "from loss import *\n",
    "import community as community_louvain\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "def train(g, features, n_classes, in_feats, n_edges, labels,train_mask,val_mask,test_mask,Q,cuda):\n",
    "    #sethyperparameter\n",
    "    dropout = 0.0\n",
    "    gpu = 0\n",
    "    lr = 5e-2\n",
    "    n_epochs = 2000\n",
    "    n_hidden =8  # 隐藏层节点的数量\n",
    "    n_layers = 0 # 输入层 + 输出层的数量\n",
    "    weight_decay = 5e-4  # 权重衰减\n",
    "    self_loop = True  # 自循环\n",
    "\n",
    "\n",
    "    #run single train of some model\n",
    "    degs = g.in_degrees().float()\n",
    "    norm = torch.pow(degs, -0.5)\n",
    "    norm[torch.isinf(norm)] = 0\n",
    "\n",
    "    if cuda:\n",
    "        torch.cuda.set_device(gpu)\n",
    "        features = features.cuda()\n",
    "        labels = labels.cuda()\n",
    "        g=g.to('cuda:0')\n",
    "        train_mask = train_mask.cuda()\n",
    "        val_mask = val_mask.cuda()\n",
    "\n",
    "    if cuda:\n",
    "        norm = norm.cuda()\n",
    "    # g.ndata['norm'] = norm.unsqueeze(1)\n",
    "\n",
    "    model = GCN(g,\n",
    "                in_feats,\n",
    "                n_hidden,\n",
    "                n_classes,\n",
    "                n_layers,\n",
    "                F.relu,\n",
    "                dropout)\n",
    "\n",
    "    for p in model.parameters():\n",
    "        print(p)\n",
    "\n",
    "    print(model)\n",
    "    # kernal_weights_analysis(model)\n",
    "\n",
    "\n",
    "    # use crossentropyLoss as loss, must consider the permutations,\n",
    "    # loss_fcn = torch.th.nn.CrossEntropyLoss()\n",
    "    loss_fcn = ModularityScore(n_classes, cuda)\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    for p in loss_fcn.parameters():\n",
    "        print(p)\n",
    "\n",
    "    #optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    optimizer = torch.optim.SGD(model.parameters(),lr = lr)\n",
    "    # train and evaluate (with modularity score and labels)\n",
    "    dur = []\n",
    "    M=[]\n",
    "    #P= [[1],[2],[3],[4],[5],[6]]\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        t0 = time.time()\n",
    "        C_hat = model(features)\n",
    "        #use train_mask to train\n",
    "        loss = loss_fcn(C_hat[val_mask],Q['val'])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #C_out=C_construction(model,features)\n",
    "\n",
    "        #use eval_mask to see overfitting\n",
    "        modularity_score=evaluate_M(C_hat[train_mask],Q['train'],cuda)\n",
    "        dur.append(time.time() - t0)\n",
    "        if epoch % 100 == 0:\n",
    "            #record modularity\n",
    "            #for i,p in enumerate(model.parameters()):\n",
    "            #    #print(p)\n",
    "            #    P[i].append(np.mean(np.abs(p.grad.cpu().detach().numpy())))\n",
    "            M.append(str(-loss.item()))\n",
    "            acc_1 = evaluate(model, features, labels, val_mask)\n",
    "            acc_2 = evaluate(model, features, 1 - labels, val_mask)\n",
    "            acc = max(acc_1, acc_2)\n",
    "            #acc=0.5\n",
    "            print(\"Epoch {} | Time(s) {} | Eval_Modularity {} | Train_Modularity {} | Eval_Accuracy {} | \"\n",
    "                  \"ETputs(KTEPS) {}\".format(epoch, np.mean(dur),modularity_score, -loss,\n",
    "                                                acc, n_edges / np.mean(dur) / 1000))\n",
    "\n",
    "    C_out=C_construction(model,features,test_mask)\n",
    "    print(C_out)\n",
    "    modularity_score=evaluate_M(C_out,Q['test'],cuda)\n",
    "    with open('modularity_history.txt','w') as f:\n",
    "        for line in M:\n",
    "            f.write(line+'\\n')\n",
    "    f.close()\n",
    "\n",
    "def main():\n",
    "    gpu=0\n",
    "    if gpu < 0:\n",
    "        cuda = False\n",
    "    else:\n",
    "        cuda = True\n",
    "    #prepare training data, set hyperparameters\n",
    "    # load cora_binary, train_masks,val_masks,test_masks are used for future accuracy comparement with supervised algorithm\n",
    "    #g, features, n_classes, in_feats, n_edges,labels = load_cora_binary()\n",
    "    g, features, n_classes, in_feats, n_edges, labels = load_kara()\n",
    "    #g, features, n_classes, in_feats, n_edges, labels=load_les_miserables()\n",
    "    #g, features, n_classes, in_feats, n_edges, labels = load_citation_graph()\n",
    "\n",
    "    #graph visualization\n",
    "\n",
    "    #visualize(labels,g)\n",
    "    n = len(labels)\n",
    "    if 'train_mask' not in g.ndata:\n",
    "        train_mask = [True] * n\n",
    "        train_mask=th.BoolTensor(train_mask)\n",
    "    else:\n",
    "        train_mask=g.ndata['train_mask']\n",
    "    if 'val_mask' not in g.ndata:\n",
    "        val_mask = [True] * n\n",
    "        val_mask=th.BoolTensor(train_mask)\n",
    "    else:\n",
    "        val_mask=g.ndata['val_mask']\n",
    "    if 'test_mask' not in g.ndata:\n",
    "        test_mask = [True] * n\n",
    "        test_mask=th.BoolTensor(test_mask)\n",
    "    else:\n",
    "        test_mask=g.ndata['test_mask']\n",
    "\n",
    "    #calculate matrix Q, initial community attachment C (with overlap)\n",
    "\n",
    "    #overwrite n_classes\n",
    "    n_classes=4\n",
    "    #construct Q['train'], Q['eval'],Q['test'] seperately\n",
    "    Q={}\n",
    "    Q['train'] = Q2(g,train_mask)\n",
    "    Q['train'] = th.from_numpy(Q['train'])\n",
    "    Q['val']= Q2(g,val_mask)\n",
    "    Q['val'] = th.from_numpy(Q['val'])\n",
    "    Q['test'] = Q2(g, test_mask)\n",
    "    Q['test'] = th.from_numpy(Q['test'])\n",
    "\n",
    "    #generate random input features\n",
    "\n",
    "    nx_g =  nx.karate_club_graph()\n",
    "    partition = community_louvain.best_partition(nx_g)\n",
    "    n_classes=np.max(list(partition.values()))+1\n",
    "    C_init = Q['train'][0:n_classes] * 0\n",
    "    C_init = C_init.T\n",
    "    for node in partition.keys():\n",
    "        C_init[node][partition[node]]=1\n",
    "\n",
    "    #try C*C.T\n",
    "    features=C_init.float()\n",
    "    #features=th.matmul(features,features.t())\n",
    "    in_feats=features.shape[1]\n",
    "\n",
    "    print(C_init)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    train(g, features, n_classes, in_feats, n_edges, labels,train_mask,val_mask,test_mask,Q,cuda)\n",
    "\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
